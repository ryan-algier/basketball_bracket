{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a922044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>G</th><th>W</th><th>ADJOE</th><th>ADJDE</th><th>BARTHAG</th><th>EFG_O</th><th>EFG_D</th><th>TOR</th><th>TORD</th><th>ORB</th><th>DRB</th><th>FTR</th><th>FTRD</th><th>2P_O</th><th>2P_D</th><th>3P_O</th><th>3P_D</th><th>ADJ_T</th><th>WAB</th><th>SEED</th><th>POSTSEASON_WINS</th></tr><tr><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>40</td><td>33</td><td>123.3</td><td>94.9</td><td>0.9531</td><td>52.6</td><td>48.1</td><td>15.4</td><td>18.2</td><td>40.7</td><td>30.0</td><td>32.3</td><td>30.4</td><td>53.9</td><td>44.6</td><td>32.7</td><td>36.2</td><td>71.7</td><td>8.6</td><td>1</td><td>5</td></tr><tr><td>40</td><td>36</td><td>129.1</td><td>93.6</td><td>0.9758</td><td>54.8</td><td>47.7</td><td>12.4</td><td>15.8</td><td>32.1</td><td>23.7</td><td>36.2</td><td>22.4</td><td>54.8</td><td>44.7</td><td>36.5</td><td>37.5</td><td>59.3</td><td>11.3</td><td>1</td><td>5</td></tr><tr><td>40</td><td>33</td><td>114.4</td><td>90.4</td><td>0.9375</td><td>53.9</td><td>47.7</td><td>14.0</td><td>19.5</td><td>25.5</td><td>24.9</td><td>30.7</td><td>30.0</td><td>54.7</td><td>46.8</td><td>35.2</td><td>33.2</td><td>65.9</td><td>6.9</td><td>3</td><td>5</td></tr><tr><td>38</td><td>31</td><td>115.2</td><td>85.2</td><td>0.9696</td><td>53.5</td><td>43.0</td><td>17.7</td><td>22.8</td><td>27.4</td><td>28.7</td><td>32.9</td><td>36.6</td><td>52.8</td><td>41.9</td><td>36.5</td><td>29.7</td><td>67.5</td><td>7.0</td><td>3</td><td>5</td></tr><tr><td>39</td><td>37</td><td>117.8</td><td>86.3</td><td>0.9728</td><td>56.6</td><td>41.1</td><td>16.2</td><td>17.1</td><td>30.0</td><td>26.2</td><td>39.0</td><td>26.9</td><td>56.3</td><td>40.0</td><td>38.2</td><td>29.0</td><td>71.5</td><td>7.7</td><td>1</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "┌─────┬─────┬───────┬───────┬───┬───────┬──────┬──────┬─────────────────┐\n",
       "│ G   ┆ W   ┆ ADJOE ┆ ADJDE ┆ … ┆ ADJ_T ┆ WAB  ┆ SEED ┆ POSTSEASON_WINS │\n",
       "│ --- ┆ --- ┆ ---   ┆ ---   ┆   ┆ ---   ┆ ---  ┆ ---  ┆ ---             │\n",
       "│ i64 ┆ i64 ┆ f64   ┆ f64   ┆   ┆ f64   ┆ f64  ┆ i64  ┆ i64             │\n",
       "╞═════╪═════╪═══════╪═══════╪═══╪═══════╪══════╪══════╪═════════════════╡\n",
       "│ 40  ┆ 33  ┆ 123.3 ┆ 94.9  ┆ … ┆ 71.7  ┆ 8.6  ┆ 1    ┆ 5               │\n",
       "│ 40  ┆ 36  ┆ 129.1 ┆ 93.6  ┆ … ┆ 59.3  ┆ 11.3 ┆ 1    ┆ 5               │\n",
       "│ 40  ┆ 33  ┆ 114.4 ┆ 90.4  ┆ … ┆ 65.9  ┆ 6.9  ┆ 3    ┆ 5               │\n",
       "│ 38  ┆ 31  ┆ 115.2 ┆ 85.2  ┆ … ┆ 67.5  ┆ 7.0  ┆ 3    ┆ 5               │\n",
       "│ 39  ┆ 37  ┆ 117.8 ┆ 86.3  ┆ … ┆ 71.5  ┆ 7.7  ┆ 1    ┆ 5               │\n",
       "└─────┴─────┴───────┴───────┴───┴───────┴──────┴──────┴─────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import polars.selectors as cs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pl.read_csv('../input_data/model_data.csv')\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9594cec",
   "metadata": {},
   "source": [
    "## Create a bunch of univarirate regression models and see which is best\n",
    "\n",
    "\n",
    "https://www.datacamp.com/tutorial/sklearn-linear-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf19b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg_r2(df, x_var):\n",
    "\n",
    "    ## create a pipeline to automatically do a standard scaler and linear regression\n",
    "    linear_reg_pipe = Pipeline([('scaler', StandardScaler()), ('linreg', LinearRegression())])\n",
    "\n",
    "    x = df.select(x_var)\n",
    "    y = df.select('POSTSEASON_WINS')\n",
    "\n",
    "    ## Standard 80/20 test/train split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=84305)\n",
    "\n",
    "    ## call the pipeline to get the score\n",
    "    r2 = linear_reg_pipe.fit(x_train, y_train).score(x_test, y_test)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc77541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'G': 0.215,\n",
       " 'W': 0.224,\n",
       " 'ADJOE': 0.088,\n",
       " 'ADJDE': 0.154,\n",
       " 'BARTHAG': 0.151,\n",
       " 'EFG_O': -0.12,\n",
       " 'EFG_D': 0.069,\n",
       " 'TOR': -0.064,\n",
       " 'TORD': -0.004,\n",
       " 'ORB': 0.057,\n",
       " 'DRB': -0.018,\n",
       " 'FTR': -0.01,\n",
       " 'FTRD': -0.022,\n",
       " '2P_O': -0.118,\n",
       " '2P_D': 0.042,\n",
       " '3P_O': -0.031,\n",
       " '3P_D': 0.03,\n",
       " 'ADJ_T': -0.003,\n",
       " 'WAB': 0.222,\n",
       " 'SEED': 0.195}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cols_r2 = {}\n",
    "test_cols = df.select(pl.exclude('POSTSEASON_WINS')).columns\n",
    "for x_var in test_cols:\n",
    "    r2 = linear_reg_r2(df, x_var)\n",
    "    test_cols_r2[x_var] = round(r2, 3)\n",
    "\n",
    "test_cols_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc7103",
   "metadata": {},
   "source": [
    "Things we learn:\n",
    "* Top performers: \n",
    "    * G: games, positive correlation (makes sense, more games = made it further in conf tourney) \n",
    "    * W: wins, makes sense, more regular season wins are better\n",
    "    * ADJDE: adjusted defense, perhaps defense does win championships?\n",
    "    * BARTHAG: Power rating - should be a good indicator if its accurate\n",
    "    * WAB: wins above bubble - makes sense, if you are beating teams that barely missed the tourney you should beat a decent amount that did make it\n",
    "    * SEED: we already saw top seeds are going to win more\n",
    "\n",
    "* Note: there might be some collinearity going on when dive deeper - won't good seeds be good at all this other stuff?\n",
    "\n",
    "* Poor performers: TORD, FTR, ADJ_T, Year\n",
    "    * TORD: turnover percentage committed (steal rate)\n",
    "    * FTR: free throw rate - how often you get to the line - officiating can be different\n",
    "    * ADJ_T: adjusted tempo - different teams have different styles, no style is superior overall\n",
    "\n",
    "* A lot of the O stats are negatively correlated with wins, thats a bit unexpected\n",
    "\n",
    "More variables that could be helpful in future analysis now that we are thinking about some of these:\n",
    "* Win percentage (W/G)\n",
    "* Strength of Schedule\n",
    "* Strength of Victory\n",
    "* Quadrant 1-4 wins and losses (this is used as part of the criteria for picking tournament teams, would be intersting to see if it actually resulted in picking teams that do better in the tournament)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d48e6fa",
   "metadata": {},
   "source": [
    "## Multivariate Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7326cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up the model and all the variables:\n",
    "\n",
    "x = df.select(pl.all().exclude('POSTSEASON_WINS'))\n",
    "y = df.select('POSTSEASON_WINS')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=84305)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_s = scaler.fit_transform(x_train)\n",
    "x_test_s = scaler.transform(x_test)\n",
    "\n",
    "multi_lin_reg_model = LinearRegression()\n",
    "multi_lin_reg_model.fit(x_train_s, y_train)\n",
    "\n",
    "y_pred = multi_lin_reg_model.predict(x_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87b19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_coefficients(x, model):\n",
    "\n",
    "    cols = x.columns\n",
    "    coefs = model.coef_.flatten().tolist()\n",
    "\n",
    "    df = pl.DataFrame({'Vars':cols, 'Coef': coefs})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbdf3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.4262298601758958\n",
      "Adj R2: 0.40634181373485234\n",
      "Intercept: [0.94481605]\n",
      "RMSE: 0.9209903275505485\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Vars</th><th>Coef</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;G&quot;</td><td>-0.218592</td></tr><tr><td>&quot;W&quot;</td><td>0.832233</td></tr><tr><td>&quot;ADJOE&quot;</td><td>1.858793</td></tr><tr><td>&quot;ADJDE&quot;</td><td>-1.692908</td></tr><tr><td>&quot;BARTHAG&quot;</td><td>-1.453127</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;3P_O&quot;</td><td>-0.302339</td></tr><tr><td>&quot;3P_D&quot;</td><td>0.382467</td></tr><tr><td>&quot;ADJ_T&quot;</td><td>-0.023519</td></tr><tr><td>&quot;WAB&quot;</td><td>-0.824328</td></tr><tr><td>&quot;SEED&quot;</td><td>-0.10245</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 2)\n",
       "┌─────────┬───────────┐\n",
       "│ Vars    ┆ Coef      │\n",
       "│ ---     ┆ ---       │\n",
       "│ str     ┆ f64       │\n",
       "╞═════════╪═══════════╡\n",
       "│ G       ┆ -0.218592 │\n",
       "│ W       ┆ 0.832233  │\n",
       "│ ADJOE   ┆ 1.858793  │\n",
       "│ ADJDE   ┆ -1.692908 │\n",
       "│ BARTHAG ┆ -1.453127 │\n",
       "│ …       ┆ …         │\n",
       "│ 3P_O    ┆ -0.302339 │\n",
       "│ 3P_D    ┆ 0.382467  │\n",
       "│ ADJ_T   ┆ -0.023519 │\n",
       "│ WAB     ┆ -0.824328 │\n",
       "│ SEED    ┆ -0.10245  │\n",
       "└─────────┴───────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "intercept = multi_lin_reg_model.intercept_\n",
    "\n",
    "n= len(x_train)\n",
    "p= len(x.columns)\n",
    "adj_r2 = 1- ((1-r2) * (n-1)/(n-p-1))\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R2: {r2}\")\n",
    "print(f\"Adj R2: {adj_r2}\")\n",
    "print(f\"Intercept: {intercept}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "model_coefficients(x, multi_lin_reg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba848e7",
   "metadata": {},
   "source": [
    "## Based on these results, we can explain about 42% of the variance in post season games won with the variables used in the model. Not too bad for something that should be difficult to predict.\n",
    "\n",
    "## The RMSE is about 1, so we will be off by about a game on average which isn't terrible\n",
    "\n",
    "### We can do one more model using the important features we saw in the univariate example and compare to see if they actually do close to as good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a4f54",
   "metadata": {},
   "source": [
    "### There is definitely too many variables here and we could do some more for feature importance testing. However, the goal for now is just to set things up. Create some models and use many different techniques, so let's do some other models first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a565747",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up the model and all the variables:\n",
    "x = df.select(['G', 'W', 'ADJDE', 'BARTHAG', 'WAB', 'SEED'])\n",
    "y = df.select('POSTSEASON_WINS')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=84305)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_s = scaler.fit_transform(x_train)\n",
    "x_test_s = scaler.transform(x_test)\n",
    "\n",
    "multi_lin_reg_model = LinearRegression()\n",
    "multi_lin_reg_model.fit(x_train_s, y_train)\n",
    "\n",
    "y_pred = multi_lin_reg_model.predict(x_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce9f707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.2965820405822863\n",
      "Adj R2: 0.28944074150190346\n",
      "Intercept: [0.94481605]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Vars</th><th>Coef</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;G&quot;</td><td>0.078634</td></tr><tr><td>&quot;W&quot;</td><td>0.445253</td></tr><tr><td>&quot;ADJDE&quot;</td><td>-0.061</td></tr><tr><td>&quot;BARTHAG&quot;</td><td>0.065414</td></tr><tr><td>&quot;WAB&quot;</td><td>-0.388223</td></tr><tr><td>&quot;SEED&quot;</td><td>-0.760608</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 2)\n",
       "┌─────────┬───────────┐\n",
       "│ Vars    ┆ Coef      │\n",
       "│ ---     ┆ ---       │\n",
       "│ str     ┆ f64       │\n",
       "╞═════════╪═══════════╡\n",
       "│ G       ┆ 0.078634  │\n",
       "│ W       ┆ 0.445253  │\n",
       "│ ADJDE   ┆ -0.061    │\n",
       "│ BARTHAG ┆ 0.065414  │\n",
       "│ WAB     ┆ -0.388223 │\n",
       "│ SEED    ┆ -0.760608 │\n",
       "└─────────┴───────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "intercept = multi_lin_reg_model.intercept_\n",
    "\n",
    "n= len(x_train)\n",
    "p= len(x.columns)\n",
    "adj_r2 = 1- ((1-r2) * (n-1)/(n-p-1))\n",
    "\n",
    "print(f\"R2: {r2}\")\n",
    "print(f\"Adj R2: {adj_r2}\")\n",
    "print(f\"Intercept: {intercept}\")\n",
    "model_coefficients(x, multi_lin_reg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This model does not do as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basketball-bracket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
